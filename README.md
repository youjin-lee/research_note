# Research Note

This is for study related to Interpretable Machine Learning.


num | title | author | year | paper rink | note rink
---- | ---- | ---- | ---- | ---- | ----
1 | On Pixel-Wise Explanations for Non-Linear Classifier Decisions by Layer-Wise Relevance Propagation | Sebastian Bach | PlosONE2015 | [LRP](https://pdfs.semanticscholar.org/17a2/73bbd4448083b01b5a9389b3c37f5425aac0.pdf?_ga=2.203325009.177220768.1611018563-57653733.1606442592) | [Note](https://drive.google.com/file/d/1YIakz1pZ69Zfcrd6ncU5SosyWE3uBTCR/view?usp=sharing)
2 | Learning Important Features Through Propagating Activation Differences| Avanti Shrikumar | ICML2017 | [DeepLIFT](https://arxiv.org/pdf/1704.02685.pdf) | [Note](https://drive.google.com/file/d/1FbCtEbHD-5mZ_3tZt8dZYdko6vD01bSr/view?usp=sharing)
3 | Grad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization | Ramprasaath R. Selvaraju | IJCV2019 | [Grad_CAM](https://arxiv.org/pdf/1610.02391.pdf) | [Note](https://drive.google.com/file/d/1zQHj8hRCtJAI7B6kxvACCFS_OOrKakCM/view?usp=sharing)
4 | "Why Should I Trust You?": Explaining the Predictions of Any Classifier | Marco Tulio Ribeiro | 2016 | [LIME](https://arxiv.org/pdf/1602.04938.pdf) | [Note](https://drive.google.com/file/d/1K_koIvaUdy2d2c1RMb2En5g3-N-hREzJ/view?usp=sharing)
5 | Examples are not Enough, Learn to Criticize!Criticism for Interpretability | Been Kim | NIPS2016 | [MMD](https://beenkim.github.io/papers/KIM2016NIPS_MMD.pdf) | [Note](https://drive.google.com/file/d/1guMTtrhLF8H6iLMVZjUJ9i_MC7Wn7Ugw/view?usp=sharing)
6 | Relative Attributing Propagation:Interpreting the Comparative Contributions of Individual Units in Deep Neural Networks | Woo-Jeoung Nam | AAAI2020 | [RAP](https://arxiv.org/pdf/1904.00605.pdf) | [Note](https://drive.google.com/file/d/16BTSaOOZF1RgpSyLs6Cy--Flh8sE0qQM/view?usp=sharing)
